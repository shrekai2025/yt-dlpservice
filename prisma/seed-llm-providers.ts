/**
 * Prisma Seed Script - LLM Providers
 *
 * åˆå§‹åŒ–è¯­è¨€æ¨¡åž‹ä¾›åº”å•†æ•°æ®
 */

import { PrismaClient } from '@prisma/client'

const prisma = new PrismaClient()

async function main() {
  console.log('ðŸŒ± Seeding LLM Providers data...')

  // ==================== Tuzi è¯­è¨€æ¨¡åž‹ä¾›åº”å•† ====================
  console.log('Creating Tuzi LLM provider...')

  const tuziProvider = await prisma.lLMProvider.upsert({
    where: { slug: 'tuzi' },
    update: {},
    create: {
      name: 'Tuzi',
      slug: 'tuzi',
      description: 'å…”å­API - æä¾›å¤šç§è¯­è¨€æ¨¡åž‹æœåŠ¡',
      isActive: true,
      sortOrder: 1,
    },
  })

  console.log('âœ“ Tuzi provider created')

  // ==================== ç«¯ç‚¹ ====================
  console.log('Creating endpoints...')

  const chatCompletionsEndpoint = await prisma.lLMEndpoint.upsert({
    where: {
      providerId_name: {
        providerId: tuziProvider.id,
        name: 'Chat Completions'
      }
    },
    update: {
      type: 'openai',
    },
    create: {
      providerId: tuziProvider.id,
      name: 'Chat Completions',
      url: 'https://api.tu-zi.com/v1/chat/completions',
      type: 'openai',
      description: 'OpenAI å…¼å®¹çš„èŠå¤©è¡¥å…¨æŽ¥å£',
      isActive: true,
      sortOrder: 1,
    },
  })

  const messagesEndpoint = await prisma.lLMEndpoint.upsert({
    where: {
      providerId_name: {
        providerId: tuziProvider.id,
        name: 'Messages'
      }
    },
    update: {
      type: 'claude',
    },
    create: {
      providerId: tuziProvider.id,
      name: 'Messages',
      url: 'https://api.tu-zi.com/v1/messages',
      type: 'claude',
      description: 'Claude Messages API',
      isActive: true,
      sortOrder: 2,
    },
  })

  console.log('âœ“ Endpoints created')

  // ==================== æ¨¡åž‹ ====================
  console.log('Creating models...')

  await prisma.lLMModel.upsert({
    where: {
      endpointId_slug: {
        endpointId: chatCompletionsEndpoint.id,
        slug: 'gemini-2-5-pro'
      }
    },
    update: {},
    create: {
      endpointId: chatCompletionsEndpoint.id,
      name: 'gemini-2.5-pro',
      slug: 'gemini-2-5-pro',
      description: 'Google Gemini 2.5 Pro æ¨¡åž‹',
      isActive: true,
      sortOrder: 1,
    },
  })

  await prisma.lLMModel.upsert({
    where: {
      endpointId_slug: {
        endpointId: chatCompletionsEndpoint.id,
        slug: 'gpt-5'
      }
    },
    update: {},
    create: {
      endpointId: chatCompletionsEndpoint.id,
      name: 'gpt-5',
      slug: 'gpt-5',
      description: 'OpenAI GPT-5 æ¨¡åž‹',
      isActive: true,
      sortOrder: 2,
    },
  })

  // Messages endpoint æ¨¡åž‹
  await prisma.lLMModel.upsert({
    where: {
      endpointId_slug: {
        endpointId: messagesEndpoint.id,
        slug: 'claude-sonnet-4-5-thinking-all'
      }
    },
    update: {},
    create: {
      endpointId: messagesEndpoint.id,
      name: 'claude-sonnet-4-5-thinking-all',
      slug: 'claude-sonnet-4-5-thinking-all',
      description: 'Claude Sonnet 4.5 Thinking All æ¨¡åž‹',
      isActive: true,
      sortOrder: 1,
    },
  })

  console.log('âœ“ Models created')

  console.log('âœ¨ LLM Providers seed completed!')
}

main()
  .catch((e) => {
    console.error('Error seeding LLM providers:', e)
    process.exit(1)
  })
  .finally(async () => {
    await prisma.$disconnect()
  })
